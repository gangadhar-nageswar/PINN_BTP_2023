{"cells":[{"cell_type":"markdown","metadata":{"id":"llx0I8S9ix-2"},"source":["# **Libraries and Dependencies**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17948,"status":"ok","timestamp":1665055779903,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"},"user_tz":-330},"id":"FZU2tjpvjPL6","outputId":"467928b4-4887-4cd8-8483-c00720ea1727"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyDOE2\n","  Downloading pyDOE2-1.3.0.tar.gz (19 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE2) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE2) (1.7.3)\n","Building wheels for collected packages: pyDOE2\n","  Building wheel for pyDOE2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyDOE2: filename=pyDOE2-1.3.0-py3-none-any.whl size=25539 sha256=3978e100498fc895890785012c7eb9d9bfc97d3d501f8d90acaddaaf46f4fd53\n","  Stored in directory: /root/.cache/pip/wheels/49/91/2d/d08e80806bf7756193541f6c03c0492af288fcd6158d3d0998\n","Successfully built pyDOE2\n","Installing collected packages: pyDOE2\n","Successfully installed pyDOE2-1.3.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting plotting\n","  Downloading plotting-0.0.7-py3-none-any.whl (13 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from plotting) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from plotting) (1.3.5)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from plotting) (0.11.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->plotting) (1.21.6)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->plotting) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->plotting) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->plotting) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->plotting) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->plotting) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->plotting) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->plotting) (2022.2.1)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->plotting) (1.7.3)\n","Installing collected packages: plotting\n","Successfully installed plotting-0.0.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pygad\n","  Downloading pygad-2.18.1-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pygad) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pygad) (3.2.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->pygad) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->pygad) (1.15.0)\n","Installing collected packages: pygad\n","Successfully installed pygad-2.18.1\n"]}],"source":["! pip install pyDOE2 #Latin Hypercube Sampling\n","! pip install plotting\n","! pip install pygad"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32448,"status":"ok","timestamp":1665055812345,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"},"user_tz":-330},"id":"ps3AZqnu9XBo","outputId":"8bd4d4df-3a19-496b-e5f0-6d43bb60136c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2666,"status":"ok","timestamp":1665055815005,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"},"user_tz":-330},"id":"wh0mH9W9h6W7"},"outputs":[],"source":["import sys\n","sys.path.insert(0, '../Utilities/')\n","\n","import torch\n","from collections import OrderedDict\n","\n","from pyDOE2 import lhs\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.io\n","from scipy.interpolate import griddata\n","# from plotting import newfig, savefig\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","import matplotlib.gridspec as gridspec\n","import time\n","\n","np.random.seed(1234)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665055815006,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"},"user_tz":-330},"id":"mLg6_gcWiQM_"},"outputs":[],"source":["# CUDA support \n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')"]},{"cell_type":"markdown","metadata":{"id":"I597Le6yi4F5"},"source":["# **Physics-informed Neural Networks**"]},{"cell_type":"code","execution_count":77,"metadata":{"executionInfo":{"elapsed":858,"status":"ok","timestamp":1665057860590,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"},"user_tz":-330},"id":"rg2zU76XiRBB"},"outputs":[],"source":["# the deep neural network\n","class DNN(torch.nn.Module):\n","    def __init__(self, layers):\n","        super(DNN, self).__init__()\n","        \n","        # parameters\n","        self.depth = len(layers) - 1\n","        \n","        # set up layer order dict\n","        self.activation = torch.nn.Tanh\n","        \n","        layer_list = list()\n","        for i in range(self.depth - 1): \n","            layer = torch.nn.Linear(layers[i], layers[i+1])\n","            torch.nn.init.xavier_normal_(layer.weight.data, gain=1.0)\n","            torch.nn.init.zeros_(layer.bias.data)\n","\n","            layer_list.append(\n","                ('layer_%d' % i, layer)\n","            )\n","            layer_list.append(('activation_%d' % i, self.activation()))\n","            # layer_list.append(('dropout_%d'%i, torch.nn.Dropout(0.005)))\n","\n","            # layer_list.append(('normalisation_%d' % i, torch.nn.BatchNorm1d(layers[i+1])))\n","            # layer_list.append(('normalisation_%d' % i, torch.nn.layerNorm(layers[i+1])))\n","\n","        layer_list.append(\n","            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n","        )\n","        layerDict = OrderedDict(layer_list)\n","        \n","        # deploy layers\n","        self.layers = torch.nn.Sequential(layerDict)\n","        \n","    def forward(self, x):\n","        out = self.layers(x)\n","        return out\n"]},{"cell_type":"code","execution_count":78,"metadata":{"executionInfo":{"elapsed":621,"status":"ok","timestamp":1665057870168,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"},"user_tz":-330},"id":"-dVFg-gciRTs"},"outputs":[],"source":["# the physics-guided neural network\n","class PhysicsInformedNN():\n","    def __init__(self, X_u, u, X_f, layers, lb, ub, nu, X_star):\n","        \n","        # boundary conditions\n","        self.lb = torch.tensor(lb).float().to(device)\n","        self.ub = torch.tensor(ub).float().to(device)\n","        \n","        self.nu = X_u.shape[0]\n","        self.nf = X_f.shape[0]\n","\n","        # data\n","        self.x_u = torch.tensor(X_u[:, 0:1], requires_grad=True).float().to(device)\n","        self.t_u = torch.tensor(X_u[:, 1:2], requires_grad=True).float().to(device)\n","        self.x_f = torch.tensor(X_f[:, 0:1], requires_grad=True).float().to(device)\n","        self.t_f = torch.tensor(X_f[:, 1:2], requires_grad=True).float().to(device)\n","        self.u = torch.tensor(u).float().to(device)\n","\n","        # # grid points\n","        self.num_x = 256\n","        self.num_t = 100\n","        self.build_grid()\n","\n","        self.layers = layers\n","        self.nu = nu\n","        \n","        # deep neural networks\n","        self.dnn = DNN(layers).to(device)\n","        \n","        # optimizers: using the same settings\n","        self.optimizer = torch.optim.LBFGS(\n","            self.dnn.parameters(), \n","            lr=1.0, \n","            max_iter=20, \n","            max_eval=20, \n","            history_size=50,\n","            tolerance_grad=1e-5, \n","            tolerance_change=1.0 * np.finfo(float).eps,\n","            line_search_fn=\"strong_wolfe\"       # can be \"strong_wolfe\"\n","        )\n","\n","        self.num_epochs = 400\n","        \n","        global selfiter\n","        selfiter = 0\n","\n","        self.set_adaptive_col_params()\n","\n","        #random seeds\n","        self.lhs_rs = 0\n","        torch.manual_seed(0)\n","        np.random.seed(1234)\n","\n","    def build_grid(self):\n","        grid_x = np.zeros(shape=(1, self.num_x))\n","        grid_x[0] = lb[0] + ((ub[0]-lb[0])/(self.num_x - 1))*np.arange(self.num_x)\n","        grid_t = np.zeros(shape=(1, self.num_t))\n","        grid_t[0] = lb[1] + ((ub[1]-lb[1])/(self.num_t - 1))*np.arange(self.num_t)\n","\n","        gX, gT = np.meshgrid(grid_x, grid_t)\n","        G = np.hstack((gX.flatten()[:,None], gT.flatten()[:,None]))\n","\n","        self.grid_x = torch.tensor(G[:, 0:1], requires_grad=True).float().to(device)\n","        self.grid_t = torch.tensor(G[:, 1:2], requires_grad=True).float().to(device)      \n","\n","    def set_adaptive_col_params(self):\n","        self.proxy = \"adapt-r\"\n","        self.gamma = 0.0\n","        self.T = 100\n","        self.e = 10\n","        self.temp = 5\n","\n","    def net_u(self, x, t):\n","        X_temp = torch.cat([x, t], dim=1)\n","\n","        # X = torch.tensor([x, t], requires_grad=True).float().to(device)\n","        # X = torch.tensor([-0.5, 0.5], requires_grad=True).float().to(device)\n","\n","        u = self.dnn(X_temp)\n","        return u\n","\n","    def net_f(self, x, t):\n","        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n","        u = self.net_u(x, t)\n","        \n","        u_t = torch.autograd.grad(\n","            u, t, \n","            grad_outputs=torch.ones_like(u),\n","            retain_graph=True,\n","            create_graph=True,\n","            allow_unused=True\n","        )[0]\n","\n","        u_x = torch.autograd.grad(\n","            u, x, \n","            grad_outputs=torch.ones_like(u),\n","            retain_graph=True,\n","            create_graph=True,\n","            allow_unused=True\n","        )[0]\n","\n","        u_xx = torch.autograd.grad(\n","            u_x, x, \n","            grad_outputs=torch.ones_like(u_x),\n","            retain_graph=True,\n","            create_graph=True,\n","            allow_unused=True\n","        )[0]\n","        \n","        f = u_t + u * u_x - self.nu * u_xx\n","\n","        return f\n","    \n","    def grad_value(self, x, t):\n","        u = self.net_u(x, t)\n","        \n","        u_t = torch.autograd.grad(\n","            u, t, \n","            grad_outputs=torch.ones_like(u),\n","            retain_graph=True,\n","            create_graph=True,\n","            allow_unused=True\n","        )[0]\n","\n","        u_x = torch.autograd.grad(\n","            u, x, \n","            grad_outputs=torch.ones_like(u),\n","            retain_graph=True,\n","            create_graph=True,\n","            allow_unused=True\n","        )[0]\n","        \n","        grad_tensor = torch.sqrt(torch.square(u_x) + torch.square(u_t))\n","        \n","        return grad_tensor\n","\n","    def proxy_func(self):\n","        prob = np.zeros(shape=(self.num_x, self.num_t))\n","\n","        start = time.time()\n","        \n","        if self.proxy == 'adapt-r':\n","            prob_proxy = self.net_f(self.grid_x, self.grid_t)\n","        elif self.proxy == 'adapt-g':\n","            prob_proxy = self.grad_value(self.grid_x, self.grid_t)\n","        \n","        # prob_proxy = torch.exp(abs(prob_proxy)/self.temp)\n","        # max_value = prob_proxy.max()\n","        # print(\"max value: {}\".format(max_value))\n","        # prob_proxy /= max_value\n","\n","        prob = np.transpose(np.reshape(abs(prob_proxy).cpu().detach().numpy(), (self.num_t, self.num_x)))\n","\n","        # for j in range(self.num_t):\n","        #   for i in range(self.num_x):\n","        #     prob[i][j] = (abs(prob_proxy[j*self.num_x + i][0])).cpu().detach().numpy()\n","        \n","        # prob = abs(res).cpu().detach().numpy()\n","\n","        return prob/prob.sum()\n","\n","    def sample_uniform(self, size):\n","\n","        x_f_train1 = self.lb[0].item() + (self.ub[0].item() - self.lb[0].item())*lhs(1, size, random_state=self.lhs_rs)\n","        t_f_train1 = self.lb[1].item() + (self.ub[1].item() - self.lb[1].item())*lhs(1, size)\n","\n","        return x_f_train1, t_f_train1\n","    \n","    def sample_proxy(self, size):\n","\n","        # normalise the array again\n","        self.prob /= self.prob.sum()\n","        flat = self.prob.flatten()\n","\n","        x_f_train2 = np.zeros(shape=(size, 1))\n","        t_f_train2 = np.zeros(shape=(size, 1))\n","\n","        for s in range(size):\n","            sample_index = np.random.choice(a=flat.size, p=flat)\n","            index = np.unravel_index(sample_index, self.prob.shape)\n","\n","            x = self.lb[0] + (self.ub[0] - self.lb[0]) * index[0] / (self.num_x)\n","            t = self.lb[1] + (self.ub[1] - self.lb[1]) * index[1] / (self.num_t)\n","\n","            x_f_train2[s][0] = x\n","            t_f_train2[s][0] = t\n","\n","        return x_f_train2, t_f_train2\n","\n","    def loss_func(self):\n","\n","        global train_error\n","        \n","        self.optimizer.zero_grad()\n","        \n","        u_pred = self.net_u(self.x_u, self.t_u)\n","        f_pred = self.net_f(self.x_f, self.t_f)\n","\n","        self.loss_u = torch.mean((self.u - u_pred) ** 2)\n","        self.loss_f = torch.mean(f_pred ** 2)\n","        \n","        loss = self.loss_u + self.loss_f\n","        \n","        loss.backward()\n","\n","        global selfiter\n","        selfiter += 1\n","        # if self.iter % 100 == 0:\n","        print(\n","            'Iter %d, Loss: %.5e, Loss_u: %.5e, Loss_f: %.5e' % (selfiter, loss.item(), self.loss_u.item(), self.loss_f.item())\n","        )\n","        \n","        train_error.append(loss.item())\n","\n","        return loss\n","    \n","    def adaptive_train(self):\n","        # set the model training mode \"on\"\n","        self.dnn.train()\n","\n","        self.prob = np.ones(shape=(self.num_x, self.num_t)) / (self.num_x * self.num_t)\n","\n","        for epoch_index in range(self.num_epochs):\n","            new_prob = self.proxy_func()\n","            self.prob = new_prob + self.gamma * self.prob\n","            self.prob /= self.prob.sum()\n","\n","            if epoch_index % self.e == 0:\n","                x_f2, t_f2 = self.sample_proxy(int(self.nf))\n","\n","                self.x_f = torch.tensor(x_f2, requires_grad=True).float().to(device)\n","                self.t_f = torch.tensor(t_f2, requires_grad=True).float().to(device)\n","\n","            # Backward and optimize\n","            self.optimizer.step(self.loss_func)\n","            \n","            # # get a test error\n","            # global test_error\n","            # u_pred, f_pred = model.predict(X_star)\n","\n","            # error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n","            # test_error.append(error_u)\n","        \n","        return None\n","    \n","    def vanilla_train(self):\n","        # set the model training mode \"on\"\n","        self.dnn.train()\n","\n","        for epoch_index in range(self.num_epochs):\n","            self.optimizer.step(self.loss_func)\n","    \n","            \n","    def predict(self, X):\n","        x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device)\n","        t = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n","\n","        self.dnn.eval()\n","        u = self.net_u(x, t)\n","        f = self.net_f(x, t)\n","        u = u.detach().cpu().numpy()\n","        f = f.detach().cpu().numpy()\n","        return u, f"]},{"cell_type":"markdown","metadata":{"id":"8wkb6umMi8h_"},"source":["# **Configurations**"]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"BM5gZy5gHzwR","executionInfo":{"status":"ok","timestamp":1665057871062,"user_tz":-330,"elapsed":16,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1665057871062,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"},"user_tz":-330},"id":"hCbkmjYliRZW","outputId":"faffe8bb-9e9c-49ed-ab29-28f3d8c40027"},"outputs":[{"output_type":"stream","name":"stdout","text":["type of t: <class 'numpy.ndarray'> || shape: (100, 1)\n","type of X: <class 'numpy.ndarray'> || shape: (100, 256)\n","type of T: <class 'numpy.ndarray'> || shape: (100, 256)\n","type of X_star: <class 'numpy.ndarray'> || shape: (25600, 2)\n"]}],"source":["nu = 0.01/np.pi\n","noise = 0.0        \n","\n","train_error = []\n","test_error = []\n","\n","selfiter = 0\n","\n","N_u = 100\n","N_f = 1000\n","n_neurs = 20\n","layers = [2, n_neurs, n_neurs, n_neurs, n_neurs, n_neurs, n_neurs, n_neurs, n_neurs, 1]\n","\n","data = scipy.io.loadmat('/content/drive/MyDrive/SEM - 7/BTP/data/burgers_shock.mat')\n","\n","t = data['t'].flatten()[:,None]\n","x = data['x'].flatten()[:,None]\n","\n","print(\"type of t: {} || shape: {}\".format(type(t), t.shape))\n","\n","Exact = np.real(data['usol']).T\n","\n","X, T = np.meshgrid(x,t)\n","print(\"type of X: {} || shape: {}\".format(type(X), X.shape))\n","print(\"type of T: {} || shape: {}\".format(type(T), T.shape))\n","\n","X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n","print(\"type of X_star: {} || shape: {}\".format(type(X_star), X_star.shape))\n","\n","u_star = Exact.flatten()[:,None]              \n","\n","# Doman bounds\n","lb = X_star.min(0)\n","ub = X_star.max(0)\n","mu = X_star.mean()\n","var = X_star.var()    \n","\n","xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n","uu1 = Exact[0:1,:].T\n","xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n","uu2 = Exact[:,0:1]\n","xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n","uu3 = Exact[:,-1:]\n","\n","X_u_train = np.vstack([xx1, xx2, xx3])\n","\n","X_f_train = lb + (ub-lb)*lhs(2, N_f)\n","# X_f_train = (lhs(2, N_f) - mu) / var\n","\n","X_f_train = np.vstack((X_f_train, X_u_train))\n","u_train = np.vstack([uu1, uu2, uu3])\n","\n","idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n","X_u_train = X_u_train[idx, :]\n","u_train = u_train[idx,:]\n","\n","#u_pred, f_pred = model.predict(X_star)\n","\n","#error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n","#print('Error u: %e' % (error_u))                     \n","\n","#U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n","#Error = np.abs(Exact - U_pred)"]},{"cell_type":"markdown","metadata":{"id":"c1fi_ecfjB0m"},"source":["# **Training**"]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1665057871062,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"},"user_tz":-330},"id":"fZgoy9FcXoYq","outputId":"b52dd007-9595-4bbc-e13f-b7ed15e8f2a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["-1.0 1.0\n","0.0 0.99\n"]}],"source":["print(lb[0], ub[0])\n","print(lb[1], ub[1])"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"L_hnkbjQiReL","executionInfo":{"status":"ok","timestamp":1665057871063,"user_tz":-330,"elapsed":12,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"}}},"outputs":[],"source":["model = PhysicsInformedNN(X_u_train, u_train, X_f_train, layers, lb, ub, nu, X_star)"]},{"cell_type":"code","execution_count":83,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"r3E8I_xEiRid","executionInfo":{"status":"ok","timestamp":1665057871063,"user_tz":-330,"elapsed":12,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"}},"outputId":"b8346d8f-7f18-42bb-b46d-c17559ed2aef"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m<ipython-input-78-ac0a4810c511>\u001b[0m in \u001b[0;36madaptive_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mnew_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_prob\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-78-ac0a4810c511>\u001b[0m in \u001b[0;36mproxy_func\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adapt-r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mprob_proxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adapt-g'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mprob_proxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-78-ac0a4810c511>\u001b[0m in \u001b[0;36mnet_f\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnet_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;34m\"\"\" The pytorch autograd version of calculating residual \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         u_t = torch.autograd.grad(\n","\u001b[0;32m<ipython-input-78-ac0a4810c511>\u001b[0m in \u001b[0;36mnet_u\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# X = torch.tensor([-0.5, 0.5], requires_grad=True).float().to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-77-017b7a6c77cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.76 GiB total capacity; 13.95 GiB already allocated; 5.75 MiB free; 13.95 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["%%time\n","torch.cuda.empty_cache()\n","model.adaptive_train()"]},{"cell_type":"code","execution_count":84,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"FMZoVK7SiRmZ","executionInfo":{"status":"error","timestamp":1665057871063,"user_tz":-330,"elapsed":9,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"}},"outputId":"e540fe1a-2700-406b-82eb-8135347ebf6d"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-84-e0abcf71ed69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mu_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0merror_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_star\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mu_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_star\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error u: %e'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-78-ac0a4810c511>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-78-ac0a4810c511>\u001b[0m in \u001b[0;36mnet_u\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# X = torch.tensor([-0.5, 0.5], requires_grad=True).float().to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-77-017b7a6c77cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.76 GiB total capacity; 13.95 GiB already allocated; 5.75 MiB free; 13.95 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["u_pred, f_pred = model.predict(X_star)\n","\n","error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n","print('Error u: %e' % (error_u))                     \n","\n","U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n","Error = np.abs(Exact - U_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dVUSWFvMiRqN","executionInfo":{"status":"aborted","timestamp":1665057871063,"user_tz":-330,"elapsed":8,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"}}},"outputs":[],"source":["\"\"\" The aesthetic setting has changed. \"\"\"\n","\n","####### Row 0: u(t,x) ##################    \n","\n","fig = plt.figure(figsize=(9, 5))\n","ax = fig.add_subplot(111)\n","\n","h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n","              extent=[t.min(), t.max(), x.min(), x.max()], \n","              origin='lower', aspect='auto')\n","divider = make_axes_locatable(ax)\n","cax = divider.append_axes(\"right\", size=\"5%\", pad=0.10)\n","cbar = fig.colorbar(h, cax=cax)\n","cbar.ax.tick_params(labelsize=15) \n","\n","ax.plot(\n","    X_u_train[:,1], \n","    X_u_train[:,0], \n","    'kx', label = 'Data (%d points)' % (u_train.shape[0]), \n","    markersize = 4,  # marker size doubled\n","    clip_on = False,\n","    alpha=1.0\n",")\n","\n","line = np.linspace(x.min(), x.max(), 2)[:,None]\n","ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n","ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n","ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n","\n","ax.set_xlabel('$t$', size=20)\n","ax.set_ylabel('$x$', size=20)\n","ax.legend(\n","    loc='upper center', \n","    bbox_to_anchor=(0.9, -0.05), \n","    ncol=5, \n","    frameon=False, \n","    prop={'size': 15}\n",")\n","ax.set_title('$u(t,x)$', fontsize = 20) # font size doubled\n","ax.tick_params(labelsize=15)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"jbhD5EASjH0x"},"source":["# **Visualizations**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lKWSK9wYiRtl","executionInfo":{"status":"aborted","timestamp":1665057871064,"user_tz":-330,"elapsed":8,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"}}},"outputs":[],"source":["####### Row 1: u(t,x) slices ################## \n","\n","\"\"\" The aesthetic setting has changed. \"\"\"\n","\n","fig = plt.figure(figsize=(14, 10))\n","ax = fig.add_subplot(111)\n","\n","gs1 = gridspec.GridSpec(1, 3)\n","gs1.update(top=1-1.0/3.0-0.1, bottom=1.0-2.0/3.0, left=0.1, right=0.9, wspace=0.5)\n","\n","ax = plt.subplot(gs1[0, 0])\n","ax.plot(x,Exact[25,:], 'b-', linewidth = 2, label = 'Exact')       \n","ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n","ax.set_xlabel('$x$')\n","ax.set_ylabel('$u(t,x)$')    \n","ax.set_title('$t = 0.25$', fontsize = 15)\n","ax.axis('square')\n","ax.set_xlim([-1.1,1.1])\n","ax.set_ylim([-1.1,1.1])\n","\n","for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n","             ax.get_xticklabels() + ax.get_yticklabels()):\n","    item.set_fontsize(15)\n","\n","ax = plt.subplot(gs1[0, 1])\n","ax.plot(x,Exact[50,:], 'b-', linewidth = 2, label = 'Exact')       \n","ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n","ax.set_xlabel('$x$')\n","ax.set_ylabel('$u(t,x)$')\n","ax.axis('square')\n","ax.set_xlim([-1.1,1.1])\n","ax.set_ylim([-1.1,1.1])\n","ax.set_title('$t = 0.50$', fontsize = 15)\n","ax.legend(\n","    loc='upper center', \n","    bbox_to_anchor=(0.5, -0.15), \n","    ncol=5, \n","    frameon=False, \n","    prop={'size': 15}\n",")\n","\n","for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n","             ax.get_xticklabels() + ax.get_yticklabels()):\n","    item.set_fontsize(15)\n","\n","ax = plt.subplot(gs1[0, 2])\n","ax.plot(x,Exact[75,:], 'b-', linewidth = 2, label = 'Exact')       \n","ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n","ax.set_xlabel('$x$')\n","ax.set_ylabel('$u(t,x)$')\n","ax.axis('square')\n","ax.set_xlim([-1.1,1.1])\n","ax.set_ylim([-1.1,1.1])    \n","ax.set_title('$t = 0.75$', fontsize = 15)\n","\n","for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n","             ax.get_xticklabels() + ax.get_yticklabels()):\n","    item.set_fontsize(15)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkRy6dQc-Gyk","executionInfo":{"status":"aborted","timestamp":1665057871064,"user_tz":-330,"elapsed":8,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"}}},"outputs":[],"source":["import matplotlib\n","\n","x_axis = [i for i in range(1,len(train_error)+1)]\n","\n","new_train_error = np.log(train_error)\n","plt.plot(x_axis, new_train_error)\n","# plt.ylim(1e-4, 1)\n","plt.title(\"train_error error\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCzyLm5YO3SB","executionInfo":{"status":"aborted","timestamp":1665057871064,"user_tz":-330,"elapsed":2510,"user":{"displayName":"Nageswar Venkata Sai Gangadhar","userId":"02855835275532238793"}}},"outputs":[],"source":["x_col = model.x_f.detach().cpu().numpy()\n","t_col = model.t_f.detach().cpu().numpy()\n","\n","plt.scatter(x_col, t_col)\n","plt.title(\"collocation points: {}- vanilla\".format(N_f))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1alIKFDvFGHVJM6ZUl9RspfvjIPDR0KRe","timestamp":1663607205979}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}